{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HLSSb7Qly6xf"
   },
   "source": [
    "# TRANSFER LEARNING\n",
    "\n",
    "In this exercise, We will use the Splits API and its concepts which we looked at in the week 2 lecture videos. Also we will look at some additional ways of loading things using tensorflow hub.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and set up the splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do this if your tfds is below version 3.x and restart the kernel\n",
    "!pip install tensorflow-datasets==3.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from os import getcwd\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tfds.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The next code block will download the mobilenet model from TensorFlow Hub, and use its learned features, extracted as feature_extractor and set to be fine tuned by making them trainable. We have already downloaded it for you but feel free to use the commented part to download the latest version from the tfhub.dev website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tSW2AcBLuiHv"
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub \n",
    "\n",
    "model_selection = (\"mobilenet_v2\", 224, 1280) \n",
    "handle_base, pixels, FV_SIZE = model_selection\n",
    "IMAGE_SIZE = (pixels, pixels)\n",
    "\n",
    "# You can also use directly to download from the source.\n",
    "\n",
    "# MODULE_HANDLE =\"https://tfhub.dev/google/tf2-preview/{}/feature_vector/4\".format(handle_base)\n",
    "# feature_extractor = hub.KerasLayer(MODULE_HANDLE,\n",
    "#                                    input_shape=IMAGE_SIZE + (3,))\n",
    "\n",
    "# We have already downloaded the data for you\n",
    "feature_extractor = hub.KerasLayer('mobilenet_feature_vector',input_shape=IMAGE_SIZE + (3,))\n",
    "feature_extractor.trainable = True  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset\n",
    "You need to use subsets of the original data, which is entirely in the 'train' split. I.E. 'train' contains 25000 records.\n",
    "\n",
    "Split it up so that you get\n",
    "\n",
    "- The first 10% is your 'new' training set\n",
    "- The last 10% is your validation and test sets, split down the middle \n",
    "    - i.e. the first half of the last 10% is validation\n",
    "    - the second half is test\n",
    "    \n",
    "These 3 recordsets should be called `train_examples`, `validation_examples` and `test_examples` respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QUSLZO8IuEtt"
   },
   "outputs": [],
   "source": [
    "# EXERCISE: Split the dataset\n",
    "\n",
    "filePath = f\"{getcwd()}/../tmp2\"\n",
    "\n",
    "splits = [#DESCRIBE YOUR SPLITS HERE#]\n",
    "    \n",
    "# Remember to use `cats_vs_dogs:4.*.*` as dataset as 4.0 support the new splits api\n",
    "# https://www.tensorflow.org/datasets/catalog/cats_vs_dogs\n",
    "# It has been downloaded for you so remember to use the data_dir parameter else it will try to download the dataset and give you error\n",
    "\n",
    "splits, info = tfds.load(#YOUR CODE HERE)\n",
    "\n",
    "(train_examples, validation_examples, test_examples) = splits\n",
    "\n",
    "# This will take some time to print\n",
    "train_len = len(list(train_examples))\n",
    "validation_len = len(list(validation_examples))\n",
    "test_len = len(list(test_examples))\n",
    "print(train_len)\n",
    "print(validation_len)\n",
    "print(test_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected Output\n",
    "```\n",
    "2326\n",
    "1163\n",
    "1163\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LtSJorjivpS9"
   },
   "outputs": [],
   "source": [
    "num_examples = 2500\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nkh5t21-uZFs"
   },
   "outputs": [],
   "source": [
    "# This will turn the 3 sets into batches\n",
    "# so we can train\n",
    "# This code should not be changed\n",
    "\n",
    "def format_image(features):\n",
    "    image = features['image']\n",
    "    image = tf.image.resize(image, IMAGE_SIZE) / 255.0\n",
    "    return  image, features['label']\n",
    "    \n",
    "BATCH_SIZE =  32\n",
    "\n",
    "train_batches = train_examples.shuffle(num_examples).map(format_image).batch(BATCH_SIZE)\n",
    "validation_batches = validation_examples.map(format_image).batch(BATCH_SIZE)\n",
    "test_batches = test_examples.map(format_image).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rmyQ207suyGY"
   },
   "outputs": [],
   "source": [
    "# The new model will take the features from the mobilenet via transfer learning\n",
    "# And add a new dense layer at the bottom, with 2 classes -- for cats and dogs\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "        feature_extractor,\n",
    "        tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dLIwqtilvBcN"
   },
   "outputs": [],
   "source": [
    "# EXERCISE: Train the model\n",
    "\n",
    "# Compile the model with adam optimizer and sparse categorical crossentropy, \n",
    "# and track the accuracy metric\n",
    "    \n",
    "model.compile(#YOUR CODE HERE)\n",
    "\n",
    "# Train it for a number of epochs. You should not need many (max 5)\n",
    "# Train on the train_Batches, and validation on the validation_batches\n",
    "    \n",
    "EPOCHS = #YOUR CODE HERE\n",
    "\n",
    "history = model.fit(#YOUR CODE HERE#)\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3jkG0zBHvEnP"
   },
   "outputs": [],
   "source": [
    "# EXERCISE: Evaluate the model\n",
    "\n",
    "# Evaluate the model on the test batches\n",
    "eval_results = model.evaluate(#YOUR CODE HERE#)\n",
    "\n",
    "# And print the results. You should have >90% accuracy\n",
    "for metric, value in zip(model.metrics_names, eval_results):\n",
    "    print(metric + ': {:.4}'.format(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now click the 'Submit Assignment' button above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When you're done or would like to take a break, please run the two cells below to save your work and close the Notebook. This frees up resources for your fellow learners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "<!-- Save the notebook -->\n",
    "IPython.notebook.save_checkpoint();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "<!-- Shutdown and close the notebook -->\n",
    "window.onbeforeunload = null\n",
    "window.close();\n",
    "IPython.notebook.session.delete();"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Week 2 Exercise Question.ipynb",
   "provenance": []
  },
  "coursera": {
   "course_slug": "data-pipelines-tensorflow",
   "graded_item_id": "UxyXw",
   "launcher_item_id": "dKnh5"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
